---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
library(dagitty)
dev.off()
```

# Chapter 5 - The Many Variables & The Spurious Waffles

What is the difference between causal and spurious correlation and how do you define it. As you may see that two variables may be correlated, although it does not mean that one affect the other.

Therefore we are going to use multiple regression, to account for effects. Even though it can overcome multiple regression, it can also create a spurious relationship.

We are going to use DAGs as a backdoor criterion, to find the causes.

## Spurious Associations

This section elaborates on the difference between causal and spurious relationships.

This is an example

```{r 5.1}
# load data and copy
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
# standardize variables
d$A <- scale( d$MedianAgeMarriage )
d$D <- scale( d$Divorce )
d$M <- scale( d$Marriage )
```

```{r 5.3}
m5.1 <- quap(
  alist(
    D ~ dnorm( mu , sigma ) ,
    mu <- a + bA * A ,
    a ~ dnorm( 0 , 0.2 ) ,
    bA ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
  )
  ,data = d)
```

The following shows plausibile regression lines given the priors.

```{r 5.4}
par(mfrow = c(1,1))
set.seed(10)
prior <- extract.prior( m5.1 )
mu <- link( m5.1 , post=prior , data=list( A=c(-2,2) ) )
plot( NULL , xlim=c(-2,2) , ylim=c(-2,2),main = "Simulateting priors")
for ( i in 1:50 ) lines( c(-2,2) , mu[i,] , col=col.alpha("black",0.4) )
```

Now we can make the posterior prediction.

```{r 5.5}
# compute percentile interval of mean
A_seq <- seq( from=-3 , to=3.2 , length.out=30 )
mu <- link( m5.1 , data=list(A=A_seq) )
mu.mean <- apply( mu ,MARGIN =  2,FUN = mean )
mu.PI <- apply( mu ,MARGIN =  2 ,FUN = PI )

# plot it all
plot( D ~ A , data=d , col=rangi2,main = "Posterior prediction")
lines( A_seq , mu.mean , lwd=2 )
shade( mu.PI , A_seq )
```

This follows up by expressing that one must be cautious about what variables that are included and if two or more variables correlate, is it merely because of a shared causal effect that the model does not account for?

### Testable implications

From the DAG's we are able to see the relations and we assume the direction of causality. Naturally these causalities are what we want to model.

For this DAGs (directed acyclic graphs) can be used. In the following DAG we see that in the left, A has direct influence on D and M, while also an indirect relationship flowing through M.

On the right A influence D and M while M and D are independent but has the same parent. Thus a change in A will lead to a change in M and D, thus if you regress the two of these on each other, it is likely that you'll find a relationship, although this is just spurious as they just appear to follow the same trends, but it cannot be said that one affects the other.

![](images/paste-37064A25.png)

The purpose of the DAG is to capture the causality. We will also see some DAG's they imply that some variable can be independent of eachother. For instance in the right DAG, we have a FORK effect, where M and D can be completely independent if we check for A, as if we know A, then we definately also know D and M. This concept is called ***implied conditional independencies***. In general these come in two forms:

1.  What variables to include in a model, when we want to identify a relationship,
2.  What variables that will become independent given the variables we intend to include.

**Defining DAGS**

```{r 5.8}
DMA_dag2 <- dagitty('dag{ D <- A -> M }')
impliedConditionalIndependencies( DMA_dag2 )
```

This (`D _||_ M | A`) means that D is independent on M conditional on A.

```{r 5.9}
DMA_dag1 <- dagitty('dag{ D <- A -> M -> D }')
impliedConditionalIndependencies( DMA_dag1 )
```

This has no conditional independence, hence there will be no output.

**How do we test these correlations ourselves?**: See the parameter comparison in the following section. We see that M variable is only correlating with D, when A is NOT in the model!

### Defining a multiple regression

Lets say we we want to measure divorce rate. Where we have marriage rate and median age at marriage.

![](images/paste-F35E9C14.png)

Then you firs specify the model for the target variable, then to define what the mean consists of, you specify the regression model. We see that alpha = the intercept with y, then $\beta_M$ is the coefficient for the marriage rate and $\beta_A$ is the coefficient for the median age at marriage.

Lastly we have the standard deviation $\sigma$, which is the standard deviation from the mean, we need this to make predictions of actual observations and not merely of the mean.

### Approximating the posterior

```{r 5.10}
m5.3 <- quap(
  alist(
    D ~ dnorm( mu , sigma ) , #The likelihood
    mu <- a + bM*M + bA*A , #Declarative
    a ~ dnorm( 0 , 0.2 ) ,
    bM ~ dnorm( 0 , 0.5 ) ,
    bA ~ dnorm( 0 , 0.5 ) ,
    sigma ~ dexp( 1 )
    ) 
  ,data = d
  )
precis( m5.3 )
```

We see that for marriage rate, it can be bothh positive and negative. While age when entering the marriage is negative, hence the higher the age the less probability of divorcing.

We saw earlier that age and marriage rate may be correlated, although we see two different effects of these, when the linear models are run separately as above.

This can also be visualized in the following.

![](images/paste-03420761.png)

![](images/paste-FD775191.png){width="275"}

Here we see that M5.2 implies that there is a relationship between marriage rate and divorce, although when we run the multiple regression, we see that this variable points both positive and negative direction (m5.3). Hence marriage rate may be spurious.

Thus we see that once we know the meadian age of marriage, there is no or little value in marriage rate, although if we dont know median age of mariage, there is still information to gain from the marriage rate.

To influence the rate of divorce, one could legislate the age at marriage, but the marriage rate will not have effect. Thus it is important to consider whether we are doing inference or prediction.

### The flow

1.  Define the model, the equations

2.  Define the priors

3.  Visualize the priors

4.  Draw samples from the posterior

5.  Making posterior predictions

    1.  Predictor residual plots. From the residuals plots we are able to see if one variable still contains information about the target value, we expect the residuals of on variable to be horizontal, if not, it means that there is still some information to gain from the variable.

    2.  Counterfactual plots, that is using standardized values.

    3.  Posterior prediction plots: Now we look at predictions for the actial observed cases.

Never analyze the residuals. Reason: we know the that the regression is internally fitting to the model, hence the rest is just the leftovers, thus they should not correlate with the target variable.

#### Posterior Prediction Plots

The benefit of checking the model against the predictions, is to see how well the model performs.

Now we can produce a simple posterior predictive check

```{r 5.15}
# call link without specifying new data
# so it uses original data
mu <- link( m5.3 )
# summarize samples across cases
mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI )
# simulate observations
# again no new data, so uses original data
D_sim <- sim( m5.3 , n=1e4 )
D_PI <- apply( D_sim , 2 , PI )
```

Now we plot the model against the actual observations.

```{r}
plot( mu_mean ~ d$D , col=rangi2 , ylim=range(mu_PI) ,
      xlab="Observed divorce" , ylab="Predicted divorce" )
abline( a=0 , b=1 , lty=2 ) #The perfect prediction
for ( i in 1:nrow(d) ) lines( rep(d$D[i],2) , mu_PI[,i] , col=rangi2 )
```

## Masked Relationship

Sometimes association between outcome of one variable is masked by another variable, hence a mediate effect. Thus, we need both variables, to describe the relationship.

![](images/paste-D70BB7FF.png)

I think that the intuition is that in a bivariate model, one predictor may not be sufficient dimensionality to predict the variance in Y. Although if you have multiple variables, then one variable can account for what the other could not.

Notice that this comes at a cost of more noise and complexity in the model, also we are able to create what is called confounding colliders.

## Categorical Variables

See example in the slides. Basiacally we can encode categoricals as:

1.  Dummies
2.  Indexes

He argued, that indexes is the best way of encoding the data.

We see that dummies create a coefficient for the given dummy, while using the index merely creates an $\alpha$ value for each category in the index. Also it makes the model simpler to write out, as you just have to specify the parameter (alpha for instance) for each index, e.g., *these are just snippets with relevant lines:*

$$
\mu_i = \alpha + \beta_mm_i
$$

$$\alpha_j \sim Normal(0,10)$$

$$\beta_m \sim Normal(0,50)$$

Which merely translates to:

$$\mu_i = \alpha_{SEX[i]}$$

$$\alpha_j \sim Normal(178,20), for j = 1...2$$

This we see that the mean is alpha given the gender, where this is just given by the normal distribution for the given gender.

# Chapter 6 - The Haunted DAG & The Causal Terror

It is called the haunting DAG, as we see that checking different variables, may create colliders, where doing inference, the actual state will be skewed, e.g., see lecture notes \@ref(lecture-notes---not-integrated-in-the-text).

The following sections elaborates on three hazards:

1.  Multicollinearity
2.  Post Treatment Bias
3.  Collider Bias

## Multicollinearity

Multicollinearity is in its core not a bad effect in your model, although you want to avoid it when doing inference. In the litterature, there is an example of predicting heights based on the length of each leg, we see that the sum of the coefficient will add to the mean of the leg length in general.

Hence overall the model will predict the right results although inference wise it is counter intuitive.

In another example we have two highly correlated predictor variables that goes the opposite way of each other. We know in this example that these are in fact explained by the same (unobserved) variable, hence when you know one, you will also know the other.

![L = lactose, F = fat. D = density. When the density is low, it has high lactose and low fat and the opposite. Thus if we know F, then we know F and L and if we know D, we will know both L and F, hence we want to only include one of the observed variables into the model.](images/paste-57ED2122.png)

In this example we saw from `precis` that when each observed variable is regressed individually the mean and compatibility intervals are far on each side of 0, although when both are included it will for both variables be centered, more or less, at 0 and have CI on both sides of 0.

***Notice that just because two variable correlate, we do not by default want to remove them!***

**Conclusion:** Just because you have many causal explanatory variables at hand, it does not mean that you should use all of them.

## Post Treatment Bias

In the book we see an example of growing plants. The experiment has the following properties:

-   They want to measure the height of the plant at different time instances, given the treatment.
-   The treatment is different soils
-   They also measure fungus

```{r}
library(dagitty)
dag <- dagitty(
    "dag {
    H0 -> H1
    T -> F
    F -> H1
    }"
    )
coordinates(dag) <- list(
  x = c(H0 = 0,H1 = 1,F = 2,T = 3),
  y = c(H0 = 1,H1 = 1,F = 1,T = 1)
)
drawdag(dag)
```

In the book two example of models with excluding and including fungus are represented. Although we see that when fungus is included, we make the relationship from treatment (T) onto height at time period 1 (H1) completely independent.

That is because there is a pipe from T to H1, and this goes through fungus, as the fungus is directly dependant on the soil treatment that the plant is given. Hence it ruins the inference.

**Why is it then called post treatment bias?** That is because the fungus is appearing as a cause of the treatment, hence after the treatment!

## Collider Bias

For this I will refer to the examples in the book about the grandchildren and the parents influence on childrens education @mcelreath2020 pp. 180 - 182.

In its basics, when we include one variable, it might also indirectly include information on an unobserverd variable that is explaning both the predictor and the target variable. Hence the effect in the predictor P will implicitly also be reflected in the model. I.e., the unobserved effect will be hidden / under the radar, thus we will not be able to distinguish this effect from the actual effect of P.

This is highly relevant to consider, lets take the example from the section in the book.

### Collider of false sorrow

Rechard has simulated some data, where each person is born with an happiness score that is fixed, and then they age every year. Every year there is also a chance of getting married. Thus the DAG looks the following:

```{r}
dag <- dagitty(
  "dag {
  M <- H
  M <- A
  }"
)
drawdag(dag)
```

Now we see that M is a collider, as we have two variables defining this. And the simulated data looks the following:

![](images/paste-EEA98756.png)

Now we know that marriage and happiness are completely unrelated (as we simulated the data).

Although we will se that if we create a model that includes both the information of mariage and age to predict hapiness, we will se a negative slope for age and positive / negative slope for not marrried vs. married.

![](images/paste-1B170C90.png){width="237"}

This is WRONG! when we look at the plot this may appear to be true, but what is actually happening is that over time, more people simply just get married, as the probability is this is increasing.

Thus is we then are to only model the effect from Age on happiness, we will see absolutely no correlation.

![](images/paste-E31826E8.png){width="235"}

That is simply because there is no relationship, when you are old you may be happy and you may be sad, this level is simply defined when you where born (at least in this simulation)

That is the collider bias, and we want to avoid introducing multiple variables that may cause these spurious relationships.

### The haunted DAG

This section is just about having a DAG, where there may be some unobserved variables. e.g.:

![](images/paste-31980612.png){width="128"}

*G = grand parents, P = parents, C = educational achievement by child. U = unobserved*

Here we see that by adding P into the model, we will include a backdoor effect, thus we add some information from U (unobserved) that is having a direct effect on C. Here the unobserved variable may be neighborhood that the child grew up in, as this has a direct effect on both the parents and the child.

In general one should be aware of these, and try to collect the relevant data, but I guess that sometimes that is simply not feasible.

## Confronting Confounding

No matter the size of the DAG, the model will consist of the following types:

![](images/paste-0D2F0876.png)

There are scenarios we want to avoid etc.

-   That I could elaborate on in the notes

The approach to analyzing the DAG:

1.  List all paths (paths disregard directions) connecting X and Y
2.  Classify each path by whether it is open or closed. A path is open unless it contains a collider
3.  Classify each path by whether it is a backdoor path. A backdoor path has an arrow entering X.
4.  If there are any open backdoor paths, decide which variable(s) to condition on o close it (if possible).

Pages 186 - 187 has examples on scenarios to avoid and how to close backdoors.

We have the following example where we want to analyze relationship on W to D.

```{r,message=FALSE}
library(dagitty)
dag_6.2 <- dagitty( "dag {
  A -> D
  A -> M -> D
  A <- S -> M
  S -> W -> D
  }"
  )
# coordinates(dag_6.2) <- list(x = c(S=3,W=3,M=2,A=0,D=0)
#                              ,y = c(S=0,W=3,M=2,A=0,D=3))
drawdag(dag_6.2)
```

There are 3 open backdoors:

1.  S -\> A
2.  S -\> M
3.  S -\> W

These all flow from S and affects either W or D. *Solution:* is to control for S, which will

We can control for this with `adjustmentSets()`, which will show variables that we should make indepent given we control for a specific variable.

```{r}
adjustmentSets( dag_6.2 , exposure="W" , outcome="D" )
```

We see that we can either control for A and M or S.

We can also let the model find the conditional independences by saying:

```{r}
impliedConditionalIndependencies(dag_6.2)
```

Thus we see that A and W are independent given we control for S.

## Exercises

### 6M1

Modify the DAG on page 186 to include the variable V, an unobserved cause of C and Y: C \<- V -\> Y. Reanalyze the DAG.How many paths connect X to Y? Which must be closed? Which variables should you condition on now?

```{r}
library(dagitty)
library(rethinking)
dag <- dagitty( "dag {
  U [unobserved]
  V [unobserved]
  X [exposure]
  Y [outcome]
  A -> U
  A -> C
  U -> B
  U -> X
  C -> B
  C -> Y
  X -> Y
  C <- V -> Y
  }"
  )
drawdag(dag)
```

Paths (undirected) from X to Y.

1.  List all paths (paths disregard directions) connecting X and Y

    1.  X,Y
    2.  X,U,B,C,Y
    3.  X,U,A,C,Y
    4.  X,U,B,C,V,Y
    5.  X,U,A,C,V,Y

2.  Classify each path by whether it is open or closed. A path is open unless it contains a collider

    -   We see that B and C are colliders, hence we will not want to touch those, as it will open up the flows to the leading effects.

3.  Classify each path by whether it is a backdoor path. A backdoor path has an arrow entering X.

    -   We see that U affects X, hence there is a backdoor. hence we want to close this relationship

4.  If there are any open backdoor paths, decide which variable(s) to condition on o close it (if possible).

    -   We see that U is a backdoor path, although it is unobserved hence we cannot adjust the model for that. (But can we adjust for A?)

### 6M3

Learning to analyze DAGs requires practice. For each of the four DAGs below, state which variables, if any, you must adjust for (conditionon) to estimate the total causal influenceof X on Y.

![](images/paste-FC71DC06.png)

1.  We must condition on Z, as the pipe from A to Y is being closed by conditioning on Z. One could

**Will this also terminate the flow directly from A to Y?**

2.  (top right): Should not condition on anything. We see that X to Y is causal and open. We see that Z is a collider, hence we dont want that included.

3.  (bottom left): We see that Z is a collider, we dont want to control for that, thus by default A and Y are independent. Hence we just include X in the model.

4.  We include X and A.

We see that in the 4th example that Z is not a collider, that is because if we list all the paths, there will not be any arrows pointing towards each other.

1.  X -\> Y
2.  X -\> Z -\> Y
3.  X \<- A -\> Z -\> Y

Where in the third example we had:

1.  X -\> Z \<- Y (We have a collider)
2.  X \<- A -\> Z \<- Y (We have a collider)
3.  X -\> Y

```{r}
library(dagitty)
library(rethinking)
dag1 <- dagitty( "dag {
  X [exposure]
  Y [outcome]
  A -> Z -> X -> Y
  Z -> Y
  A -> Y
  }"
  )

dag2 <- dagitty( "dag {
  X [exposure]
  Y [outcome]
  A -> Z -> Y
  A -> Y
  X -> Z
  X -> Y
  }"
  )

dag3 <- dagitty( "dag {
  X [exposure]
  Y [outcome]
  A -> X -> Y
  A -> Z
  X -> Z
  Y -> Z
  }"
  )

dag4 <- dagitty( "dag {
  X [exposure]
  Y [outcome]
  A -> Z -> Y
  A -> X
  X -> Y
  X -> Z
  }"
  )
adjustmentSets(x = dag1,exposure = "X",outcome = "Y")
adjustmentSets(x = dag2,exposure = "X",outcome = "Y")
adjustmentSets(x = dag3,exposure = "X",outcome = "Y")
adjustmentSets(x = dag4,exposure = "X",outcome = "Y")
```

### 6H

```{r}
library(rethinking)
library(dagitty)
data(foxes)
dfs <- foxes
dfs$group <- scale(dfs$group)
dfs$avgfood <- scale(dfs$avgfood)
dfs$groupsize <- scale(dfs$groupsize)
dfs$area <- scale(dfs$area)
dfs$group <- scale(dfs$weight)

dag <- dagitty( "dag {
  weigth [outcome]
  weigth <- groupsize
  area -> avgfood -> groupsize
  avgfood -> weigth
  }"
  )

drawdag(dag)
```

### 6H3

Use a model to infer the total causal influence of area on weight. Would increasing the **area** available to each fox make it **heavier** (healthier)? You might want to standardize the variables. Regardless, use prior predictive simulation to show that your model's prior predictions stay within the possible outcome range.

```{r}
library(rethinking)
library(dagitty)

dag3 <- dagitty( "dag {
  weigth [outcome]
  area [exposure]
  weigth <- groupsize
  area -> avgfood -> groupsize
  avgfood -> weigth
  }"
  )
drawdag(dag)
```

Possible paths:

1.  area \> avgfood \> weight
2.  area \> avgfood \> groupsize \> weight

We just need to include Area.

Now for the analysis.

```{r}
library(rethinking)
data(foxes)
d <- foxes
d$W <- standardize(d$weight)
d$A <- standardize(d$area)
m1 <- quap(
  alist(
    W ~ dnorm( mu , sigma ), #Weight is a normal distribution
    mu <- a + bA*A, #the mean weights are defined by an intercept and a slope for A (area)
    a ~ dnorm(0,0.2), #The intercept prior
    bA ~ dnorm(0,0.5), #The slope prior
    sigma ~ dexp(1) #The variance
  ), data=d )
precis(m1)
```

We see that the intercept is 0 although with a standard deviation of 0.08. We then see for each unit of area the weight is increasing by 0.02, while the standard deviation is 0.09m thus the weight is expected to both go up and down.

Thus statistically we cannot infer anything about the relationship.

### 6H4

Now infer the causal impact of adding food to a territory. Would this make foxes heavier? Which covariates do you need to adjust for to estimate the total causal influence of food.

Now we want to see if food is increasing weight, thus X is avgfood and Y is Weight

We see that there is a pipe from avgfood through groupsize, that implies that there is a direct effect from avgfood to weight, but also an indirect effect through groupsize. The task just says to measure the overall effect of food. Hence we want to construct a model only with food. We can do that as there are no backdoors to our explanatory variable.

```{r}
library(rethinking)
data(foxes)
head(foxes)
```

```{r}
d <- foxes
d$W <- standardize(d$weight)
d$AF <- standardize(d$avgfood)
m2 <- quap(
  alist(
    W ~ dnorm(mu,sigma),
    mu <- a + bAF*AF + sigma,
    a ~ dnorm(0,0.2),
    bAF ~ dnorm(0,0.5),
    sigma ~ dexp(1)
  )
  ,data = d
)
precis(m2)
```

We see that there is a great deal of uncertainty as the mean beta coefficient is -0.02, although the standard deviation suggests that it can both go up and down (the weight)

Also notice that we did find that area had no effect on weight, and it makes sense that there is cause from area to avgfood, and thus increasing avgfood is similar to increasing area, thus it is expected with no effect. Although it would also be an explanation that a larger area would enable them to roam more around, hence food density would probably have been a better variable or at least interesting.

### 6H5

Consider your own research questing. Draw a DAG to represent it. What is the testatable implications of your DAG. Are there any variables you could condition on to close all backdoor paths? Are there unobserved variables that yoy have omitted? Would a reasonable colleague imagine additional threats to causal inference that you have ignored?

Lets just take the same data as above and add groupsize instead.

```{r}
d <- foxes
d$W <- standardize(d$weight)
d$G <- standardize(d$groupsize)
m3 <- quap(
  alist(
    W ~ dnorm(mu,sigma),
    mu <- a + bG*G + sigma,
    a ~ dnorm(0,0.2),
    bG ~ dnorm(0,0.2),
    sigma ~ dexp(1)
  )
  ,data = d
)
precis(m3)
```

We see that group size tend to have a negative effect on the weight, hence by one group size unit increase standard deviation we will expect to weigh less.

## Lecture notes - not integrated in the text

There are the following types:

![](images/paste-AF9AF12A.png)

**The fork:** We see that Z is a commen cause, thus when we know the outcome of Z, there is no relationship between X and Y.

![](images/paste-6AF0B30B.png)

**The pipe:** We see that Z is a mediator. We see that if we know (Condition) on Z, we remove the relationship between X and Y.

![](images/paste-831AAB7D.png)

We see that this is very similar to the fork.

![](images/paste-59DCC9B1.png)

**The collider:** We see that there is a relationship from X to Z and Y to Z. Although if we control for Z, there is no relationship between X and Z. Thus, if we make the model as a linear regression, we will form a spurious relationship between X and Y, that we want to avoid.

The following is an example.

![](images/paste-D2249587.png){width="454"}

They must both be on, for the light to be on, but if switch is on and electicity is off, then the light is also off, hence if we know one of the parents, then we know the state of the other.

**Collider confounding:** That is to identify if there actually is a relationship between two variables that explain the target variable.

We see in the following example, we control for marriage, and the two subsets of data will make the age appear to have a negative effect on happiness, while we know that that is not true (the data was simulated.)

![](images/paste-37D535B5.png)

**Summary:**

![](images/paste-9098F7FA.png)

For the pipe we dont want to control for Z, as that will terminate the relationship from C to Y.

For the Collider we need to take care and not create a spurious relationship. We want to leave the collider alone, hence we do not touch it.
