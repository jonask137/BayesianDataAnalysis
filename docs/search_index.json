[["index.html", "Bayesian Data Analysis Notes Introduction", " Bayesian Data Analysis Notes Jonas Ringive Korsholm Introduction "],["chapter-1-golems-of-prague.html", "1 Chapter 1 - Golems of Prague", " 1 Chapter 1 - Golems of Prague This is a metaphor of having golems. These are machines that are given commands and then they will act accordingly, and do nothing else. The problem with this is that it has no background or knowledge, hence it is really up to us to make sure that it is not malfunctioning. Hence this is a metaphor for statistical models. Regarding models and hypotheses We see that a model is not the same as a hypothesis. With this there is critique on attempting to falsify the null model. That is because then you assume that something is exactly what you state in the null model. That is not true. Hence one should instead looking into falsifying the alternative model. Then what are we going to do? We are going to count the ways that an outcome can occur, to find the most probable events. This will give us bayesian distributions. These we are to explore to learn about the data and UPDATE our own beliefs. The disadvantage of bayesian approaches is the it can be cumbersome to perform. The reason that this is a small field, is that previously it has not been computationally possible. Although MCMC allows this! This is done by drawing an approximation of the original posterior distribution. Bayesian Data Analysis is about counting all the ways that the data can happen, according to assumptions. Assumptions with more ways to cause data are more plausible. CH1, p. 11 We see that the assumptions are what we put into the Golems. Hence what the Golem belief before seeing the data. Assumptions = prior beliefs. What the model assumes before What is probability? The frequentist view: This is basically traditional statistics, where we test a hypothesis based on a significance level. This relies on the data you have and the process you take. This is an objective perspective, you never carry on knowledge, it is all about the long relative frequencies. The bayesian probability: here we assume that there is nothing random. But what we call randomness is our ignorance. Hence e.g., with a coin toss, if we knew all about physics, we would always be able to predict the outcome. This implies that the bayesian view is subjective, that is also a great critique of this perception. "],["chapter-2-small-worlds-and-large-worlds.html", "2 Chapter 2 - Small worlds and Large Worlds 2.1 Models and Estimation 2.2 Exercises", " 2 Chapter 2 - Small worlds and Large Worlds The small world is the world of the golems assumptions. Bayesian golems are optimal, in the small world. The large world is the real world. No guarantee of optimality for any kind of golem. Terminoligy: Under drawing of replacement we are able to write out the possible contents Garden of Forking Data is the possible outcomes that we will see. Conjecture = the assumption of what the different observations looks like (or is constructed). e.g, we have a bag of 4 marbles, we may assume that there is 1 blue and 3 whites. In the following we are able to see what possible outcomes we expect to have. This can then be extended by a second draw: Now we see that there are 16 different paths, given the assumptions that we made (1 blue and 3 white). Now this expands exponentially, hence by including a third draw we would have 64 different outcomes. Now what? One should draw the whole garden and find the paths that can lead to the way of producing the desired output. As the number of paths increase exponentially, we quickly start to work with large counts. This is the reason, that Bayes Theorem got into this approach, as we are able to compress the counts as relative counts. We can do this with R. Lets say that we have 3, 8 and 9 ways of producing three different compositions of a bag of marbles, then we say: ways = c(3,8,9) #notice that the counts are found given the conjecture ways/sum(ways) ## [1] 0.15 0.40 0.45 Hence we see that the relative plausibility for 3 blue and 1 white is 45%, given the conjecture (the assumption of the composition of the bag) Building a model We want to: Design the model (data story) Condition on the data (update) Evaluate the model (critique) See also example with tossing globes in the following sections. priors let us say that we have a prior with absolutely no information (like traditional statistics), we do not know if it is 100% or 0% water, hence the prior looks the following: Now we introduce more information. Notice that we consecutively update priors. Prior distribution = striped and posterior distribution = solid line. We see that after the first observation (top left), there is 0 probability of 0% water, as we now know that there is water. Now we can look at the next observation, we see that it is land, now the posterior distribution is essentially centered at 0. Now lets look at a third observation, we see that the posterior is skewed to the right of the prior. We see that the more information we see, the taller (the more certain) will the distributions be. Key takeaway: the current posterior distribution will be the prior distribution for the following observation. How can one manipulate the process? We see that you can change how much the prior is updated, hence if you are certain about a prior distribution, then you can make it more difficult for the model to update this. Also we see from the example above, that the more information that is revealed, the less does the prior matter. 2.1 Models and Estimation Introduction: We see that the Bayesian Data Analysis takes the approach of having a prior probability (the probability of an event happening while ignoring the data we have at hand). Then we compute posterior probabilities as we introduce data. The posterior probabilities can be seen as a relative count of how many ways a given outcome can be replicated out of the total. The Bayesian Data Analysis can essentially be fitted with three different models: 1. Grid approximation: Good with few parameters 2. Quadratic approximation: Good with a moderate amount of parameters. Also, this is an approximate and is rarely applied. 3. Markov Chain Monte Carlo: Outperforms other models in in a high parameter scenario 4. (Analytical approach): this is often impossible. Examples will be shown during lectures, but will not be used. Remember that the Bayesian Estimate that we end up with, will always be a distribution and not a point estimate!! This is a section about models and estimation, based on chapter 1 - 3 from the book. Some terminology: Prior Distribution: This is the distribution of a prior event. E.g., lets say that we toss a coin. There are two sides hence we expect to see a normal bell curve centered in 50%. Posterior Distribution: This is basically just the prior distribution after we introduce observations. Lets say that we end up getting many consecutive heads, it implies that the probability of an outcome is actually skewed, e.g., the coin may be more heavy on one side. Hence we will see that the posterior distribution will not be centered around 50% but move to one of the sides. Therefore, you can model with (test different) prior probabilities. But the posterior probability is found after introducing data (observations/samples). Likelihood: This is just the relative number of ways that a given scenario can be produced. E.g., if you have discrete data, drawing marbles then the likelihood of some sequence is just the relative count of how you can construct such sequence. Prior probability = prior plausibility Updated plausibility = posterior probability The posterior is calculated as the following This is to be interpreted as: Average likelihood = evidens. This is summing over p. hence it ensures that the posterior distribution will sum to 1. Likelihood = ways to get the data Prior = prior ways to get the data Hence one ends up with probability of p given the new data. Assumptions when making the model Data story: Motivate the model by narrating how the data might arise. Update: Educate your model by feeding it the data. Basically the distribution for a given outcome is explored observation by observation. The more data we have seen the better should the distributions be. Evaluate: All statistical models require supervision, leading possibly to model revision. #Code 2.2 - finding likelihood dbinom(x = 6 #No. of &#39;successes&#39; water in this case ,size=9 #No. of tosses ,prob=0.5 #Probability of a given outcome (succes) ) # = 0.1640625 ## [1] 0.1640625 d for density or distribution. bi for binomial. We see that the probability of getting 6 water (and 3 land) is 16%. Given that the probability of water is 50%. The 16% is equivilent to the relative number of ways that 6 water and 3 land can be found. Notes in prior priobabilitieis. We see that oftentimes you only have one prior, and it can for instance be based on already seen data. Although a prior does not have to be based on that, one can test of different priors and see what that leads to. How to select a prior: In general we can always do better than just everything is equally likely, but notice there is no true prior. This means that a good prior is subjective, therefore, one can test with different priors and see how sensitive the model is to different priors. 2.1.1 Engines / Motors to estimate the models We are going to apply three different engines to estimate the model. 2.1.1.1 Grid approximation Here we use a grid of values to compute the likelihood of Water. This is basically just defining a range, and calculating the probabilities for the given value, then we end up being able to plot this. length = 20 # define grid p_grid &lt;- seq( from=0 , to=1 , length.out = length ) # define prior prior &lt;- rep( 1 , length ) # compute likelihood at each value in grid likelihood &lt;- dbinom(6 ,size=9 ,prob=p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting plot(p_grid ,posterior ,type=&quot;b&quot; ,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ) mtext( &quot;20 points&quot; ) abline(v = 0.67,lty = 2,col = &quot;darkgreen&quot;) mtext(text = &quot;Quap mean approximation, see next section&quot;,side = 1,at = 0.6,col = &quot;darkgreen&quot;,cex = 0.7) So we see that the probability of picking 6 times water peaks around 60% to 70%. The Grid approximation scales very badly, hence when you have a model with many variables it starts to get cumbersome to estimate. That is the reason that we go to quadratic approximation. 2.1.1.2 Quadratic approximation The quadratic approximation is basically utilizing Guassian (normal) distribution library(rethinking) globe.qa &lt;- quap( alist( W ~ dbinom( W+L ,p) , # binomial likelihood p ~ dunif(0,1) # uniform prior ) , data=list(W=6,L=3) ) # display summary of quadratic approximation precis( globe.qa ) x 0.6666664 x 0.1571339 x 0.4155361 x 0.9177966 We see that the mean is 0.67, hence the highest prior, this level is also inserted in the illustration above, to show that we end up in approximately the same place. Then the standard deviation (sd) is the spread en then the confidence intervals are shown. 2.1.1.3 Markov Chain Monte Carlo This sections does not yet go in detail with MCMC. Although the key takeaway is that quadratic approximation is also cumbersome and to some extent impossible when you have a lot of parameters. Therefore MCMC can be used instead. The following is a toy example with the same data: #R Code 2.8 n_samples &lt;- 1000 p &lt;- rep( NA , n_samples ) #Samples from the posterior distribution p[1] &lt;- 0.5 #Posterior W &lt;- 6 #Successes (Water) L &lt;- 3 #Non successes (Land) for ( i in 2:n_samples) { p_new &lt;- rnorm(1, p[i-1], 0.1) if(p_new &lt; 0) p_new &lt;- abs(p_new) if(p_new &gt; 1) p_new &lt;- 2 - p_new q0 &lt;- dbinom(W , W+L , p[i-1] ) q1 &lt;- dbinom(W , W+L , p_new ) p[i] &lt;- ifelse( runif(1) &lt; q1/q0 , p_new , p[i-1] ) } dens(p , xlim=c(0,1)) curve(dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE) 2.2 Exercises 2.2.1 2M1 Recall the globe tossing model from the chapter. Compute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for p. W, W, W W, W, W, L L, W, W, L, W, W, W They can be calculated using the same piece of code. Although we must change the number of successes and the number of tosses. length = 20 # define grid p_grid &lt;- seq( from=0 , to=1 , length.out = length ) # define prior prior &lt;- rep( 1 , length ) # compute likelihood at each value in grid likelihood &lt;- dbinom(x = 3 ,size=3 #No. of tosses ,prob=p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting par(mfrow = c(2,1)) plot(prior,type = &#39;l&#39;,main = &quot;Prior&quot;) plot(p_grid ,posterior ,type=&quot;b&quot; ,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,main = &quot;Posterior distribution&quot; ,sub = paste(length,&quot; points&quot;) ) We see that if we only draw water then we get more and more certain that there is only water. If we are to make a new toss. Then we should what we see above will be our new prior. Hence we start with a uniform prior (the stupid prior) and end up with a prior that contain information. length = 20 # define grid p_grid &lt;- seq( from=0 , to=1 , length.out = length ) # define prior prior &lt;- rep( 1 , length ) # compute likelihood at each value in grid likelihood &lt;- dbinom(x = 3 #No. of successes ,size=4 #No. of tosses ,prob=p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting par(mfrow = c(2,1)) plot(prior,type = &#39;l&#39;,main = &quot;Prior&quot;) plot(p_grid ,posterior ,type=&quot;b&quot; ,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,sub = paste(length,&quot; points&quot;) ) length = 20 # define grid p_grid &lt;- seq( from=0 , to=1 , length.out = length ) # define prior prior &lt;- rep( 1 , length ) # compute likelihood at each value in grid likelihood &lt;- dbinom(x = 5 #No. of successes ,size = 7 #No. of tosses ,prob=p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting par(mfrow = c(2,1)) plot(prior,type = &#39;l&#39;,main = &quot;Prior&quot;) plot(p_grid ,posterior ,type=&quot;b&quot; ,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,sub = paste(length,&quot; points&quot;) ) 2.2.2 2M2 Now assume a prior for p that is equal to zero when p &lt; 0.5 and is a positive constant when p ≥ 0.5. Again compute and plot the grid approximate posterior distribution for each of the sets of observations in the problem just above. With this we are going to put more information in the prior. More than just having a prior without any information. We see with this binomial (i guess you can say) technique, there will be a jump whenever the probability of water exceeds 50%. This come from the prior we set, where we expect that at least 50% of the globe is water and the rest is land, hence we think that there is a chance of having more water than land. Naturally one could set the prior to anything and see how this affect the results. length = 50 # define grid p_grid &lt;- seq( from=0 , to=1 , length.out = length ) # define prior prior &lt;- c(rep(0,length/2),rep(1,length/2)) # compute likelihood at each value in grid x = 3 size = 3 likelihood &lt;- dbinom(x = x ,size=size #No. of tosses ,prob=p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting par(mfrow = c(2,2)) plot(prior,type = &#39;l&#39;,main = &quot;Prior&quot;,sub = &quot;All use the same prior&quot;) plot(p_grid ,posterior,type=&quot;l&quot;,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,main = &quot;Posterior distribution&quot;,sub = paste(length,&quot;points, success =&quot;,x,&quot;and size =&quot;,size)) #And for the other three models x = 3 size = 4 likelihood &lt;- dbinom(x = x,size=size,prob=p_grid) unstd.posterior &lt;- likelihood * prior posterior &lt;- unstd.posterior / sum(unstd.posterior) plot(p_grid ,posterior,type=&quot;l&quot;,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,main = &quot;Posterior distribution&quot;,sub = paste(length,&quot;points, success =&quot;,x,&quot;and size =&quot;,size)) x = 5 size = 7 likelihood &lt;- dbinom(x = x,size=size,prob=p_grid) unstd.posterior &lt;- likelihood * prior posterior &lt;- unstd.posterior / sum(unstd.posterior) plot(p_grid ,posterior,type=&quot;l&quot;,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,main = &quot;Posterior distribution&quot;,sub = paste(length,&quot;points, success =&quot;,x,&quot;and size =&quot;,size)) "],["chapter-3-sampling-the-imaginary.html", "3 Chapter 3 - Sampling the Imaginary 3.1 Sampling from a grid-approximate posterior 3.2 Sampling to summarize 3.3 Sampling to simulate prediction 3.4 Exercises", " 3 Chapter 3 - Sampling the Imaginary They take the following example: We see that this is the equation for a person being vampire given that the test i positive. This is calculated by using Bayes Theorem. This can be written in code in the following: #3.1 Pr_Positive_Vampire &lt;- 0.95 #Condiational prob for positive given vampire Pr_Positive_Mortal &lt;- 0.01 #Essentially the false positive rate Pr_Vampire &lt;- 0.001 #Prior for being vampire Pr_Positive &lt;- Pr_Positive_Vampire * Pr_Vampire + Pr_Positive_Mortal * (1 - Pr_Vampire) (Pr_Vampire_Positive &lt;- Pr_Positive_Vampire*Pr_Vampire / Pr_Positive) ## [1] 0.08683729 We see that given the test being positive, there is an 8.6% chance of being vampire compared to the default 0.001. So we see that even though the test has 95% percent correctness there is in fact still only less than 10% chance that you are a vampire given the positive test. We see that the actual true rate is dependent on how many in the population that are actual vampires. A more intuitive way of writing out this can be shown as: Leading to: The Aim of the following section is to build an intuition around the approximation techniques. We see that in the example it is very simple hence one would not necessarily need the approximation techniques. Although it is suggested to start using the fitting techniques early as one will use them as soon as the problem gets just a bit more complex. 3.1 Sampling from a grid-approximate posterior Lets take an example. We are going to take 10.000 samples p_grid &lt;- seq(from=0,to=1,length.out=1000 ) prob_p &lt;- rep(1,1000) #This is the prior. It is flat = stupid prior prob_data &lt;- dbinom(6,size=9,prob=p_grid) posterior &lt;- prob_data * prob_p posterior &lt;- posterior / sum(posterior) #sum(posterior) = average likelihood print(&quot;First 10 posteriors&quot;) posterior[1:10] par(mfrow = c(2,2)) plot(p_grid,main = &quot;p_grid&quot;) #The grid plot(prob_p,main = &quot;prob_p (prior)&quot;) #Prior plot(prob_data,main = &quot;prob_data (likelihood)&quot;) #likelihood plot(posterior,main = &quot;posterior&quot;) #Posterior ## [1] &quot;First 10 posteriors&quot; ## [1] 0.000000e+00 8.433659e-19 5.381333e-17 6.111249e-16 3.423368e-15 ## [6] 1.301978e-14 3.875963e-14 9.744233e-14 2.164638e-13 4.375070e-13 Notice that the p_grid is flat. Hence the Now lets sample from the prior distribution. #Code 3.3 set.seed(1337) samples &lt;- sample(p_grid ,prob=posterior ,size=10000 #The higher the number the smoother the curve ,replace=TRUE ) #Code 3.4 par(mfrow = c(2,1)) plot(samples) library(rethinking) dens(samples) We see that the densitity plot shows the estimated probability of water on the globe. What we have seen so far: we are replicating the posterior probability of water based on the data we have at hand. This is not of much value. We are next going to use the samples to understand the posterior. 3.2 Sampling to summarize Now we see that the models work is done. Although now it is up to the analyst to interprete the posterior distribution. This includes: How much posterior probability lies below some parameter value? How much posterior probability lies between two parameter values? Which parameter value marks the lower 5% of the posterior probability? Which range of parameter values contains 90% of the posterior probability? Which parameter value has highest posterior probability? This is essentially about three things: 1) defined boundaries, 2) defined probability mass, 3) point estimates. The following sections describe these. 3.2.1 Defined Boundaries This options(scipen = 0) # add up posterior probability where p &lt; 0.5 p_grid sum(posterior[p_grid &lt; 0.5]) #Sum all posteriors where the p_grid is &lt; 50% ## [1] 0.000000000 0.001001001 0.002002002 0.003003003 0.004004004 0.005005005 ## [7] 0.006006006 0.007007007 0.008008008 0.009009009 0.010010010 0.011011011 ## [13] 0.012012012 0.013013013 0.014014014 0.015015015 0.016016016 0.017017017 ## [19] 0.018018018 0.019019019 0.020020020 0.021021021 0.022022022 0.023023023 ## [25] 0.024024024 0.025025025 0.026026026 0.027027027 0.028028028 0.029029029 ## [31] 0.030030030 0.031031031 0.032032032 0.033033033 0.034034034 0.035035035 ## [37] 0.036036036 0.037037037 0.038038038 0.039039039 0.040040040 0.041041041 ## [43] 0.042042042 0.043043043 0.044044044 0.045045045 0.046046046 0.047047047 ## [49] 0.048048048 0.049049049 0.050050050 0.051051051 0.052052052 0.053053053 ## [55] 0.054054054 0.055055055 0.056056056 0.057057057 0.058058058 0.059059059 ## [61] 0.060060060 0.061061061 0.062062062 0.063063063 0.064064064 0.065065065 ## [67] 0.066066066 0.067067067 0.068068068 0.069069069 0.070070070 0.071071071 ## [73] 0.072072072 0.073073073 0.074074074 0.075075075 0.076076076 0.077077077 ## [79] 0.078078078 0.079079079 0.080080080 0.081081081 0.082082082 0.083083083 ## [85] 0.084084084 0.085085085 0.086086086 0.087087087 0.088088088 0.089089089 ## [91] 0.090090090 0.091091091 0.092092092 0.093093093 0.094094094 0.095095095 ## [97] 0.096096096 0.097097097 0.098098098 0.099099099 0.100100100 0.101101101 ## [103] 0.102102102 0.103103103 0.104104104 0.105105105 0.106106106 0.107107107 ## [109] 0.108108108 0.109109109 0.110110110 0.111111111 0.112112112 0.113113113 ## [115] 0.114114114 0.115115115 0.116116116 0.117117117 0.118118118 0.119119119 ## [121] 0.120120120 0.121121121 0.122122122 0.123123123 0.124124124 0.125125125 ## [127] 0.126126126 0.127127127 0.128128128 0.129129129 0.130130130 0.131131131 ## [133] 0.132132132 0.133133133 0.134134134 0.135135135 0.136136136 0.137137137 ## [139] 0.138138138 0.139139139 0.140140140 0.141141141 0.142142142 0.143143143 ## [145] 0.144144144 0.145145145 0.146146146 0.147147147 0.148148148 0.149149149 ## [151] 0.150150150 0.151151151 0.152152152 0.153153153 0.154154154 0.155155155 ## [157] 0.156156156 0.157157157 0.158158158 0.159159159 0.160160160 0.161161161 ## [163] 0.162162162 0.163163163 0.164164164 0.165165165 0.166166166 0.167167167 ## [169] 0.168168168 0.169169169 0.170170170 0.171171171 0.172172172 0.173173173 ## [175] 0.174174174 0.175175175 0.176176176 0.177177177 0.178178178 0.179179179 ## [181] 0.180180180 0.181181181 0.182182182 0.183183183 0.184184184 0.185185185 ## [187] 0.186186186 0.187187187 0.188188188 0.189189189 0.190190190 0.191191191 ## [193] 0.192192192 0.193193193 0.194194194 0.195195195 0.196196196 0.197197197 ## [199] 0.198198198 0.199199199 0.200200200 0.201201201 0.202202202 0.203203203 ## [205] 0.204204204 0.205205205 0.206206206 0.207207207 0.208208208 0.209209209 ## [211] 0.210210210 0.211211211 0.212212212 0.213213213 0.214214214 0.215215215 ## [217] 0.216216216 0.217217217 0.218218218 0.219219219 0.220220220 0.221221221 ## [223] 0.222222222 0.223223223 0.224224224 0.225225225 0.226226226 0.227227227 ## [229] 0.228228228 0.229229229 0.230230230 0.231231231 0.232232232 0.233233233 ## [235] 0.234234234 0.235235235 0.236236236 0.237237237 0.238238238 0.239239239 ## [241] 0.240240240 0.241241241 0.242242242 0.243243243 0.244244244 0.245245245 ## [247] 0.246246246 0.247247247 0.248248248 0.249249249 0.250250250 0.251251251 ## [253] 0.252252252 0.253253253 0.254254254 0.255255255 0.256256256 0.257257257 ## [259] 0.258258258 0.259259259 0.260260260 0.261261261 0.262262262 0.263263263 ## [265] 0.264264264 0.265265265 0.266266266 0.267267267 0.268268268 0.269269269 ## [271] 0.270270270 0.271271271 0.272272272 0.273273273 0.274274274 0.275275275 ## [277] 0.276276276 0.277277277 0.278278278 0.279279279 0.280280280 0.281281281 ## [283] 0.282282282 0.283283283 0.284284284 0.285285285 0.286286286 0.287287287 ## [289] 0.288288288 0.289289289 0.290290290 0.291291291 0.292292292 0.293293293 ## [295] 0.294294294 0.295295295 0.296296296 0.297297297 0.298298298 0.299299299 ## [301] 0.300300300 0.301301301 0.302302302 0.303303303 0.304304304 0.305305305 ## [307] 0.306306306 0.307307307 0.308308308 0.309309309 0.310310310 0.311311311 ## [313] 0.312312312 0.313313313 0.314314314 0.315315315 0.316316316 0.317317317 ## [319] 0.318318318 0.319319319 0.320320320 0.321321321 0.322322322 0.323323323 ## [325] 0.324324324 0.325325325 0.326326326 0.327327327 0.328328328 0.329329329 ## [331] 0.330330330 0.331331331 0.332332332 0.333333333 0.334334334 0.335335335 ## [337] 0.336336336 0.337337337 0.338338338 0.339339339 0.340340340 0.341341341 ## [343] 0.342342342 0.343343343 0.344344344 0.345345345 0.346346346 0.347347347 ## [349] 0.348348348 0.349349349 0.350350350 0.351351351 0.352352352 0.353353353 ## [355] 0.354354354 0.355355355 0.356356356 0.357357357 0.358358358 0.359359359 ## [361] 0.360360360 0.361361361 0.362362362 0.363363363 0.364364364 0.365365365 ## [367] 0.366366366 0.367367367 0.368368368 0.369369369 0.370370370 0.371371371 ## [373] 0.372372372 0.373373373 0.374374374 0.375375375 0.376376376 0.377377377 ## [379] 0.378378378 0.379379379 0.380380380 0.381381381 0.382382382 0.383383383 ## [385] 0.384384384 0.385385385 0.386386386 0.387387387 0.388388388 0.389389389 ## [391] 0.390390390 0.391391391 0.392392392 0.393393393 0.394394394 0.395395395 ## [397] 0.396396396 0.397397397 0.398398398 0.399399399 0.400400400 0.401401401 ## [403] 0.402402402 0.403403403 0.404404404 0.405405405 0.406406406 0.407407407 ## [409] 0.408408408 0.409409409 0.410410410 0.411411411 0.412412412 0.413413413 ## [415] 0.414414414 0.415415415 0.416416416 0.417417417 0.418418418 0.419419419 ## [421] 0.420420420 0.421421421 0.422422422 0.423423423 0.424424424 0.425425425 ## [427] 0.426426426 0.427427427 0.428428428 0.429429429 0.430430430 0.431431431 ## [433] 0.432432432 0.433433433 0.434434434 0.435435435 0.436436436 0.437437437 ## [439] 0.438438438 0.439439439 0.440440440 0.441441441 0.442442442 0.443443443 ## [445] 0.444444444 0.445445445 0.446446446 0.447447447 0.448448448 0.449449449 ## [451] 0.450450450 0.451451451 0.452452452 0.453453453 0.454454454 0.455455455 ## [457] 0.456456456 0.457457457 0.458458458 0.459459459 0.460460460 0.461461461 ## [463] 0.462462462 0.463463463 0.464464464 0.465465465 0.466466466 0.467467467 ## [469] 0.468468468 0.469469469 0.470470470 0.471471471 0.472472472 0.473473473 ## [475] 0.474474474 0.475475475 0.476476476 0.477477477 0.478478478 0.479479479 ## [481] 0.480480480 0.481481481 0.482482482 0.483483483 0.484484484 0.485485485 ## [487] 0.486486486 0.487487487 0.488488488 0.489489489 0.490490490 0.491491491 ## [493] 0.492492492 0.493493493 0.494494494 0.495495495 0.496496496 0.497497497 ## [499] 0.498498498 0.499499499 0.500500501 0.501501502 0.502502503 0.503503504 ## [505] 0.504504505 0.505505506 0.506506507 0.507507508 0.508508509 0.509509510 ## [511] 0.510510511 0.511511512 0.512512513 0.513513514 0.514514515 0.515515516 ## [517] 0.516516517 0.517517518 0.518518519 0.519519520 0.520520521 0.521521522 ## [523] 0.522522523 0.523523524 0.524524525 0.525525526 0.526526527 0.527527528 ## [529] 0.528528529 0.529529530 0.530530531 0.531531532 0.532532533 0.533533534 ## [535] 0.534534535 0.535535536 0.536536537 0.537537538 0.538538539 0.539539540 ## [541] 0.540540541 0.541541542 0.542542543 0.543543544 0.544544545 0.545545546 ## [547] 0.546546547 0.547547548 0.548548549 0.549549550 0.550550551 0.551551552 ## [553] 0.552552553 0.553553554 0.554554555 0.555555556 0.556556557 0.557557558 ## [559] 0.558558559 0.559559560 0.560560561 0.561561562 0.562562563 0.563563564 ## [565] 0.564564565 0.565565566 0.566566567 0.567567568 0.568568569 0.569569570 ## [571] 0.570570571 0.571571572 0.572572573 0.573573574 0.574574575 0.575575576 ## [577] 0.576576577 0.577577578 0.578578579 0.579579580 0.580580581 0.581581582 ## [583] 0.582582583 0.583583584 0.584584585 0.585585586 0.586586587 0.587587588 ## [589] 0.588588589 0.589589590 0.590590591 0.591591592 0.592592593 0.593593594 ## [595] 0.594594595 0.595595596 0.596596597 0.597597598 0.598598599 0.599599600 ## [601] 0.600600601 0.601601602 0.602602603 0.603603604 0.604604605 0.605605606 ## [607] 0.606606607 0.607607608 0.608608609 0.609609610 0.610610611 0.611611612 ## [613] 0.612612613 0.613613614 0.614614615 0.615615616 0.616616617 0.617617618 ## [619] 0.618618619 0.619619620 0.620620621 0.621621622 0.622622623 0.623623624 ## [625] 0.624624625 0.625625626 0.626626627 0.627627628 0.628628629 0.629629630 ## [631] 0.630630631 0.631631632 0.632632633 0.633633634 0.634634635 0.635635636 ## [637] 0.636636637 0.637637638 0.638638639 0.639639640 0.640640641 0.641641642 ## [643] 0.642642643 0.643643644 0.644644645 0.645645646 0.646646647 0.647647648 ## [649] 0.648648649 0.649649650 0.650650651 0.651651652 0.652652653 0.653653654 ## [655] 0.654654655 0.655655656 0.656656657 0.657657658 0.658658659 0.659659660 ## [661] 0.660660661 0.661661662 0.662662663 0.663663664 0.664664665 0.665665666 ## [667] 0.666666667 0.667667668 0.668668669 0.669669670 0.670670671 0.671671672 ## [673] 0.672672673 0.673673674 0.674674675 0.675675676 0.676676677 0.677677678 ## [679] 0.678678679 0.679679680 0.680680681 0.681681682 0.682682683 0.683683684 ## [685] 0.684684685 0.685685686 0.686686687 0.687687688 0.688688689 0.689689690 ## [691] 0.690690691 0.691691692 0.692692693 0.693693694 0.694694695 0.695695696 ## [697] 0.696696697 0.697697698 0.698698699 0.699699700 0.700700701 0.701701702 ## [703] 0.702702703 0.703703704 0.704704705 0.705705706 0.706706707 0.707707708 ## [709] 0.708708709 0.709709710 0.710710711 0.711711712 0.712712713 0.713713714 ## [715] 0.714714715 0.715715716 0.716716717 0.717717718 0.718718719 0.719719720 ## [721] 0.720720721 0.721721722 0.722722723 0.723723724 0.724724725 0.725725726 ## [727] 0.726726727 0.727727728 0.728728729 0.729729730 0.730730731 0.731731732 ## [733] 0.732732733 0.733733734 0.734734735 0.735735736 0.736736737 0.737737738 ## [739] 0.738738739 0.739739740 0.740740741 0.741741742 0.742742743 0.743743744 ## [745] 0.744744745 0.745745746 0.746746747 0.747747748 0.748748749 0.749749750 ## [751] 0.750750751 0.751751752 0.752752753 0.753753754 0.754754755 0.755755756 ## [757] 0.756756757 0.757757758 0.758758759 0.759759760 0.760760761 0.761761762 ## [763] 0.762762763 0.763763764 0.764764765 0.765765766 0.766766767 0.767767768 ## [769] 0.768768769 0.769769770 0.770770771 0.771771772 0.772772773 0.773773774 ## [775] 0.774774775 0.775775776 0.776776777 0.777777778 0.778778779 0.779779780 ## [781] 0.780780781 0.781781782 0.782782783 0.783783784 0.784784785 0.785785786 ## [787] 0.786786787 0.787787788 0.788788789 0.789789790 0.790790791 0.791791792 ## [793] 0.792792793 0.793793794 0.794794795 0.795795796 0.796796797 0.797797798 ## [799] 0.798798799 0.799799800 0.800800801 0.801801802 0.802802803 0.803803804 ## [805] 0.804804805 0.805805806 0.806806807 0.807807808 0.808808809 0.809809810 ## [811] 0.810810811 0.811811812 0.812812813 0.813813814 0.814814815 0.815815816 ## [817] 0.816816817 0.817817818 0.818818819 0.819819820 0.820820821 0.821821822 ## [823] 0.822822823 0.823823824 0.824824825 0.825825826 0.826826827 0.827827828 ## [829] 0.828828829 0.829829830 0.830830831 0.831831832 0.832832833 0.833833834 ## [835] 0.834834835 0.835835836 0.836836837 0.837837838 0.838838839 0.839839840 ## [841] 0.840840841 0.841841842 0.842842843 0.843843844 0.844844845 0.845845846 ## [847] 0.846846847 0.847847848 0.848848849 0.849849850 0.850850851 0.851851852 ## [853] 0.852852853 0.853853854 0.854854855 0.855855856 0.856856857 0.857857858 ## [859] 0.858858859 0.859859860 0.860860861 0.861861862 0.862862863 0.863863864 ## [865] 0.864864865 0.865865866 0.866866867 0.867867868 0.868868869 0.869869870 ## [871] 0.870870871 0.871871872 0.872872873 0.873873874 0.874874875 0.875875876 ## [877] 0.876876877 0.877877878 0.878878879 0.879879880 0.880880881 0.881881882 ## [883] 0.882882883 0.883883884 0.884884885 0.885885886 0.886886887 0.887887888 ## [889] 0.888888889 0.889889890 0.890890891 0.891891892 0.892892893 0.893893894 ## [895] 0.894894895 0.895895896 0.896896897 0.897897898 0.898898899 0.899899900 ## [901] 0.900900901 0.901901902 0.902902903 0.903903904 0.904904905 0.905905906 ## [907] 0.906906907 0.907907908 0.908908909 0.909909910 0.910910911 0.911911912 ## [913] 0.912912913 0.913913914 0.914914915 0.915915916 0.916916917 0.917917918 ## [919] 0.918918919 0.919919920 0.920920921 0.921921922 0.922922923 0.923923924 ## [925] 0.924924925 0.925925926 0.926926927 0.927927928 0.928928929 0.929929930 ## [931] 0.930930931 0.931931932 0.932932933 0.933933934 0.934934935 0.935935936 ## [937] 0.936936937 0.937937938 0.938938939 0.939939940 0.940940941 0.941941942 ## [943] 0.942942943 0.943943944 0.944944945 0.945945946 0.946946947 0.947947948 ## [949] 0.948948949 0.949949950 0.950950951 0.951951952 0.952952953 0.953953954 ## [955] 0.954954955 0.955955956 0.956956957 0.957957958 0.958958959 0.959959960 ## [961] 0.960960961 0.961961962 0.962962963 0.963963964 0.964964965 0.965965966 ## [967] 0.966966967 0.967967968 0.968968969 0.969969970 0.970970971 0.971971972 ## [973] 0.972972973 0.973973974 0.974974975 0.975975976 0.976976977 0.977977978 ## [979] 0.978978979 0.979979980 0.980980981 0.981981982 0.982982983 0.983983984 ## [985] 0.984984985 0.985985986 0.986986987 0.987987988 0.988988989 0.989989990 ## [991] 0.990990991 0.991991992 0.992992993 0.993993994 0.994994995 0.995995996 ## [997] 0.996996997 0.997997998 0.998998999 1.000000000 ## [1] 0.1718746 We see that the sum of the first 10 probabilities, as these are below. 3.2.2 Defined Probability Mass This is about finding an interval and interpreting this. For example, we want to know the region between the 10% and 90% quantiles, or the first 80%. This can be solved by doing: #R Code 3.9 quantile(samples,0.8) #Boundaries of lower 80% posterior probability, thus it starts at 0 #R Code 3.10 quantile(samples,c(0.1,0.9)) #Or between 10% and 90% posterior probability. hence midle 80% posterior probability ## 80% ## 0.7607608 ## 10% 90% ## 0.4484484 0.8119119 These we call percentile intervals (PI). For this there is functionality in the rethinkinglibrary. PI(samples,prob = 0.5) ## 25% 75% ## 0.5415415 0.7377377 We see that this will autoamtically find the center probability of the posterior distribution. This may not be convenient if for instance the peak is outside of the region that PI return. Therefore we have the functio HPDI, which stands for highest posterior density interval. This will find the densest probability mass. This is justified, as you can end up with the same probability mass region with many combinations, hence HPDI is merely helping with this procedure. HPDI(samples,prob = 0.5) ## |0.5 0.5| ## 0.5475475 0.7417417 Now we see that it finds a more narrow region aggregating to the same probability. The following also exemplify this: Many will confuse this with a confidence interval, while they will be named compatibility or credible intervals so they are not mixed up. Criticism of traditional confidence intervals. One sees that a common interpretation of confidence intervals is that with a CI of 95%, means that there is a 95% probability of the true value lying within the interval. THIS IS WRONG, that is a Bayesian interpretation and can only be used in a Bayesian setting. This is actually about what if you repeat an experiment, then 95% of the computed intervals will include the ‘true’ value. See page 58. Criticims of ‘true’ values. Remember that you are working in a small world and thus true answers can never really be found, these belong in the large world. 3.2.3 Point Estimates Point estimates are the third and final common summary task for the posterior distribution. Often this is not wanted, as point estimates will remove valuable information. The following are examples of getting the point estimates: par(mfrow = c(1,1)) plot(x = p_grid,y = posterior,type = &#39;l&#39;,main = &quot;Posterior distribution&quot;,sub = &quot;Showing different point estimates&quot;) grid() abline(v = p_grid[ which.max(posterior) ],col = &quot;darkblue&quot;) abline(v = chainmode( samples , adj=0.01 ),col = &quot;darkgreen&quot;) abline(v = mean( samples ),col = &quot;darkred&quot;) abline(v = median( samples ),col = &quot;darkorange&quot;) legend(&quot;topleft&quot;,legend = c(&quot;max posteriod&quot;,&quot;mode&quot;,&quot;mean&quot;,&quot;median&quot;),lty = 1,col = c(&quot;darkblue&quot;,&quot;darkgreen&quot;,&quot;darkred&quot;,&quot;darkorange&quot;)) #R Code 3.14 to 3.16 p_grid[ which.max(posterior) ] chainmode( samples , adj=0.01 ) #The mode: i.e., the most often appearing value mean( samples ) median( samples ) ## [1] 0.6666667 ## [1] 0.6830388 ## [1] 0.6359439 ## [1] 0.6446446 The question is then: what point estimate to use? We can apply a loss function to support the decision. We can find a series of loss given the grid and the loss function. loss &lt;- sapply(X = p_grid ,FUN = function(d) sum(posterior * abs(d-p_grid))) And for one specific point estimate: sum(posterior * abs(0.5 - p_grid)) #0.1640626 ## [1] 0.1640626 To find the point estimate with the lowest loss one can say: p_grid[which.min(loss)] #0.6446446, equal to the median ## [1] 0.6446446 There are naturally also other loss functions, e.g., \\((d-p)^2\\), which would lead to the posterio mean. 3.3 Sampling to simulate prediction We can sample data to simulate the observations from the model. It has the following advantages: Model Design: One can sample from the prior and see what one expects. This we will look more into in a later section. Model Checking: To see if you end up with the same model. Software Validation: One can use it to simulate the data that the models was built on. To check if the model can replicate the underlying data. I guess this is to check if something is broken. Research Design: Forecasting: One can simulate what will happen in the future. The following is an overview of how to simulate observations and make model checks: 3.3.1 Dummy Data This is basically drawing data given a certain probability of the different outcomes. One must remember that the outputs of such are small world numbers. The folo dummy_w &lt;- rbinom(n = 100000 #No of observations ,size=9 #Size of each set ,prob=0.7) #70% water simplehist( dummy_w , xlab=&quot;dummy water count&quot; ) We see that we get mostly combinations with 6 or 7 water. 3.3.2 Model Checking This has two purposes: Ensure that the model fit worked correctly Evaluate the adequacy of a model for some purpose Did the software work? This is basically just to check if you have set it up correctly. Is the model adequate? There are no true models, hence you need to assess where the model fails to describe the data. One also experience that models tend to be overconfident. One wants to sample from the distribution to see if the model can be replicated. If we end up seeing very different results, then one should start considering is somthing is not taken into account. 3.4 Exercises 3.4.1 3M1 Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before. length = 100 # define grid p_grid &lt;- seq(from=0 , to=1 , length.out = length) # define prior prior &lt;- rep(1, length) #The flat (stupid) prior # compute likelihood at each value in grid likelihood &lt;- dbinom(x = 8 #Successes, water in this example ,size = 15 #No. of tosses ,prob = p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting par(mfrow = c(2,1)) plot(prior,type = &#39;l&#39;,main = &quot;Prior&quot;) plot(p_grid ,posterior ,type=&quot;l&quot; ,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,main = &quot;Posterior distribution&quot; ,sub = paste(length,&quot; points&quot;) ) abline(v = p_grid[which.max(posterior)],col = &quot;darkred&quot;,lty = 2) mtext(paste(&quot;Max =&quot;,round(p_grid[which.max(posterior)],2))) We see that the posterior distribution is now centered almost around 50%, as we almost in every second case see water. 3.4.2 3M2 Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p. First we draw 10.000 samples and then we can calculate the HDPI (higest posterior density interval) library(rethinking) samples &lt;- sample(p_grid,size=10000,replace=TRUE,prob=posterior) hdpi &lt;- rethinking::HPDI(samples,prob = 0.9) par(mfrow = c(1,1)) plot(p_grid ,posterior ,type=&quot;l&quot; ,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,main = &quot;Posterior distribution&quot; ,sub = paste(length,&quot; points&quot;) ) abline(v = hdpi[1],lty = 2) abline(v = hdpi[2],lty = 2) mtext(paste(&quot;Max =&quot;,round(p_grid[which.max(posterior)],2))) 3.4.3 3M3 Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in p. What is the probability of observing 8 water in 15 tosses? Posterior predictive check = to inspect the posterior and see if it actually makes sense. par(mfrow = c(1,2)) plot(samples) dens(samples) mean(samples) ## [1] 0.5292899 dbinom(x = 8,size = 15,prob = mean(samples)) ## [1] 0.202942 We see that there is a 0.2 probability that you select 8 water in a total of 15 tosses. 3.4.4 3M4 Using the posterior distribution constructed from the new (8/15) data, now calculate the probability of observing 6 water in 9 tosses. dbinom(x = 6,size = 9,prob = mean(samples)) ## [1] 0.19262 We see a 0.19 probability of getting 6 water in a total of 9 tosses. 3.4.5 3M5 Start over at 3M1, but now use a prior that is zero below p = 0.5 and a constant above p = 0.5. This corresponds to prior information that a majority of the Earth’s surface is water. Repeat each problem above and compare the inferences. What difference does the better prior make? If it helps, compare inferences (using both priors) to the true value p = 0.7. length = 100 # define grid p_grid &lt;- seq(from=0 , to=1 , length.out = length) # define prior prior &lt;- c(rep(0,length/2),rep(1,length/2)) # compute likelihood at each value in grid likelihood &lt;- dbinom(x = 8 #Successes, water in this example ,size = 15 #No. of tosses ,prob = p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting par(mfrow = c(2,1)) plot(prior,type = &#39;l&#39;,main = &quot;Prior&quot;) plot(p_grid ,posterior ,type=&quot;l&quot; ,xlab=&quot;probability of water&quot; ,ylab=&quot;posterior probability&quot; ,main = &quot;Posterior distribution&quot; ,sub = paste(length,&quot; points&quot;) ) abline(v = p_grid[which.max(posterior)],col = &quot;darkred&quot;,lty = 2) mtext(paste(&quot;Max =&quot;,round(p_grid[which.max(posterior)],2))) #Calculating HDPI samples &lt;- sample(p_grid,size=10000,replace=TRUE,prob=posterior) hdpi &lt;- rethinking::HPDI(samples,prob = 0.9) abline(v = hdpi[1],lty = 2,col = &quot;darkblue&quot;) abline(v = hdpi[2],lty = 2,col = &quot;darkblue&quot;) Now we would see that the probability of drawing water is relatively higher than what we have seen before. Although that does not mean that one cannot draw land and there is also a chance of drawing only land. Calculating probability of different outcomes dbinom(x = 8,size = 15,prob = mean(samples)) ## [1] 0.1711683 We see that this went from a bit above 20% to almost 17% The following scenario increased. dbinom(x = 6,size = 9,prob = mean(samples)) ## [1] 0.2554195 We see that it is higher now, we went from 0.19 to 0.25. We see that the scenario of getting relatively more water is higher. 3.4.6 3H1 Using grid approximation, compute the posterior distribution for the probability of a birth being a boy. Assume a uniform prior probability. Which parameter value maximizes the posterior probability? 1 = Male, 0 = Female. Ande birth 1 and 2 are two different datasets. library(rethinking) data(homeworkch3) sum(birth1) + sum(birth2) ## [1] 111 This means that there are 111 boys in the two datasets. length = 100 # define grid p_grid &lt;- seq( from=0 , to=1 , length.out = length ) # define prior prior &lt;- rep( 1 , length ) # compute likelihood at each value in grid likelihood &lt;- dbinom(111 ,size=200 ,prob=p_grid ) # compute product of likelihood and prior unstd.posterior &lt;- likelihood * prior # standardize the posterior, so it sums to 1 posterior &lt;- unstd.posterior / sum(unstd.posterior) #Plotting plot(prior,type = &#39;l&#39;) plot(p_grid ,posterior ,type=&quot;l&quot; ,xlab=&quot;probability of a boy&quot; ,ylab=&quot;posterior probability&quot; ) abline(v = p_grid[which.max(posterior)],col = &#39;darkgreen&#39;) 3.4.7 3H2 Using the sample function, draw 10,000 random parameter values from the posterior distribution you calculated above. Use these samples to estimate the 50%, 89%, and 97% highest posterior density intervals. samples &lt;- sample(p_grid,size=10000,replace=TRUE,prob=posterior) hdpi &lt;- rethinking::HPDI(samples,prob = 0.5) hdpi ## |0.5 0.5| ## 0.5454545 0.5858586 # |0.5 0.5| #0.5454545 0.5858586 rethinking::HPDI(samples,prob = 0.89) ## |0.89 0.89| ## 0.5050505 0.6060606 rethinking::HPDI(samples,prob = 0.97) ## |0.97 0.97| ## 0.4848485 0.6262626 3.4.8 3H3 Use rbinom to simulate 10,000 replicates of 200 births. You should end up with 10,000 numbers, each one a count of boys out of 200 births. Compare the distribution of predicted numbers of boys to the actual count in the data (111 boys out of 200 births). There are many good ways to visualize the simulations, but the dens command (part of the rethinking package) is probably the easiest way in this case. Does it look like the model fits the data well? That is, does the distribution of predictions include the actual observation as a central, likely outcome? 3.4.9 3H4 Now compare 10,000 counts of boys from 100 simulated first borns only to the number of boys in the first births, birth1. How does the model look in this light? 3.4.10 3H5 The model assumes that sex of first and second births are independent. To check this assumption, focus now on second births that followed female first borns. Compare 10,000 simulated counts of boys to only those second births that followed girls. To do this correctly, you need to count the number of first borns who were girls and simulate that many births, 10,000 times. Compare the counts of boys in your simulations to the actual observed count of boys following girls. How does the model look in this light? Any guesses what is going on in these data? "],["geocentric-models.html", "4 Geocentric Models 4.1 Why Normal distributions are normal 4.2 A language for describing models 4.3 Gaussian model of height 4.4 Linear prediction 4.5 Curves form lines 4.6 Exercises", " 4 Geocentric Models This chapter introduce lienar regression as a Bayesian procedure. Thus we will apply probability measures for intepretation, as that is what Bayesian is. 4.1 Why Normal distributions are normal This section examplifies why normal distributions are normal and how it is often seen in nature. Jesper shows an example where binomial random draws will tend to be centered around 0 as there are the most paths leading towards the middle. That is why we often find the normal distribution in real life. It express that normal distributions come from addition of random events, e.g., the result of consecutive coin tosses. Also the product of small numbers approximate addition, hence the result of such outcomes is similar to the added scenario. Although with large numbers we will tend not to get a normal distribution by finding the product hereof. The book aim to teaach a strategy to model data and not a single model just for the toolbox. 4.2 A language for describing models This chapter summarize how models are defined and defines mathematical terminalogy. Recipe of defining models Recognize the variables that you want to understand. Observable variables = data. While unobservable things = parameters, e.g., averages and rates, e.g., you dont observe GDP growth rates, but it can be deducted from assessing varaibles (observed data). Each variable can be defined in terms of other variables or in terms of a probability distribution. This enables one to learn about associations between variables. The combination of variables and their probability distributions defines a joint generative model. This can be used to simulate hypothetical observations as well as analyze real ones. Mathematical terminology: We see that \\(W \\sim Binomial(N,p)\\) means that W (water) variable is binomial, it has two outcomes, yes or no. and then we have \\(p ~ Uniform(0,1)\\), means that p (proportion of water on the globe) is between 0 and 1. Notice that the wavy symbol ~ means that the models are stochastic, i.e., there are no instances on the left that are known with certainty. I.e., W is distributed as binomial Regarding priors: The priors must be set before you see the data, as if you did not do that, then it is no more a prior. If you have no idea what to set as a prior, then you set it to some random value, e.g., making it uniform to be within a specific range. 4.3 Gaussian model of height The following is an example to understand normal distributions of normal distributions. library(rethinking) data(Howell1) d &lt;- Howell1 #d for data frame str(d) ## &#39;data.frame&#39;: 544 obs. of 4 variables: ## $ height: num 152 140 137 157 145 ... ## $ weight: num 47.8 36.5 31.9 53 41.3 ... ## $ age : num 63 63 65 41 51 35 32 27 19 54 ... ## $ male : int 1 0 0 1 0 1 0 1 0 1 ... We see that we have height, wiehgt, age and male. This can also be summarized with mean, sd, percentiles and histograms. precis(d) x 138.2635963 35.6106176 29.3443934 0.4724265 x 27.6024476 14.7191782 20.7468882 0.4996986 x 81.108550 9.360721 1.000000 0.000000 x 165.73500 54.50289 66.13500 1.00000 x ▁▁▁▁▁▁▁▂▁▇▇▅▁ ▁▂▃▂▂▂▂▅▇▇▃▂▁ ▇▅▅▃▅▂▂▁▁ ▇▁▁▁▁▁▁▁▁▇ And thus we see the distributions. We are only going to be working with people above or equal to 18 years of age. Notice that we cannot use the histograms to suggest a distribution, that is because we need to select the priors on berforehand. d2 &lt;- d[d$age &gt;= 18,] 4.3.1 The model Now we can define the model with with the following terms: \\[h_i \\sim Normal(\\mu,\\sigma)\\] \\(h_i \\sim \\mathcal{N}\\), this is exactly the same, just shortened. Meaning that height is stochastic, given the wavy character ~, it is normal with mu and sigma mean and standard deviation. The i means each element in vector h. Now we can specify the priors. this is done independently for each parameter (unobserved). It looks the following: We see that we have the likelihood that consist of the priors, which are specified afterwards. This can be plotted with. It means that the mean is centered in 178 and 20 standard deviation, thus two standard deviations (95% being 40), we will have 95% of the people within 178 +- 40. curve(dnorm(x,178,20),from = 100,to = 250,main = &#39;Mean prior&#39;) curve(dunif(x,0,50),from = -10,to = 60,main = &quot;Sigma prior&quot;) Now one can sample heights based on the two priors. samples &lt;- 10000 sample_mu &lt;- rnorm(samples,178,20) #notice we cannot take the mean of the data, as it is a prior!!! sample_sigma &lt;- runif(samples,0,50) prior_h &lt;- rnorm(samples,sample_mu,sample_sigma) dens(prior_h) One see that the mean is around the 178. The more samples we draw, the more normal will it look. Now this makes sense since the mean standard deviation is rather low, lets look at an example with a large standard deviation to the mean. samples &lt;- 10000 sample_mu &lt;- rnorm(samples,178,100) #notice we cannot take the mean of the data, as it is a prior!!! prior_h &lt;- rnorm(samples,sample_mu,sample_sigma) dens(prior_h) Now we see that the height can go all the way up to 600 and down to a negative number. When you have a lot of data instances, then such a prior is not harmfull even though it clearly expects a lot of people being very tall and some even below 0. So having an unreasonable prior is not necessarily bad. 4.3.2 Grid approximation of the posterior distribution mu.list &lt;- seq(from=150, to=160, length.out=100) sigma.list &lt;- seq(from=7, to=9, length.out=100) #Expand list, mu and sigma, post &lt;- expand.grid(mu = mu.list, sigma = sigma.list) post$LL &lt;- sapply(1:nrow(post), function(i) sum( dnorm(x = d2$height ,mean = post$mu[i] ,sd = post$sigma[i] ,log = TRUE) ) ) post$prod &lt;- post$LL + dnorm( post$mu , 178 , 20 , TRUE) + dunif(post$sigma,0, 50, TRUE) post$prob &lt;- exp(post$prod - max(post$prod)) Now, lets inspect the posterior distribution par(mfrow = c(2,1)) #A contour plot contour_xyz(post$mu, post$sigma, post$prob) #A heatmap image_xyz(x = post$mu,y = post$sigma,z = post$prob) What we get from this, is the most probable combinations of the mu and sigma. Hence we see that very often the mean will be between 154 and 155 while the standard deviation is between 7.5 and 8. 4.3.3 Sampling from the posterior Now we are going to sample from the posterior, just as in the globe tossing problem. Here we are just also to sample from the mean and standard deviation. This is done by first making a set of samples, where each row number is listed, basically just an index. Then we use the index to return the given mean and standard deviation. sample.rows &lt;- sample(1:nrow(post),size = 10000, replace = TRUE) #We can draw the same instance twice sample.mu &lt;- post$mu[sample.rows] sample.sigma &lt;- post$sigma[sample.rows] We see that post$mu and sigma is a grid ranging from respectively 150 to 160 and 7 to 9. e.g., m &lt;- matrix(post$mu,nrow = 100,ncol = 100) head(m[1:10,1:10],n = 10) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 150.0000 150.0000 150.0000 150.0000 150.0000 150.0000 150.0000 150.0000 ## [2,] 150.1010 150.1010 150.1010 150.1010 150.1010 150.1010 150.1010 150.1010 ## [3,] 150.2020 150.2020 150.2020 150.2020 150.2020 150.2020 150.2020 150.2020 ## [4,] 150.3030 150.3030 150.3030 150.3030 150.3030 150.3030 150.3030 150.3030 ## [5,] 150.4040 150.4040 150.4040 150.4040 150.4040 150.4040 150.4040 150.4040 ## [6,] 150.5051 150.5051 150.5051 150.5051 150.5051 150.5051 150.5051 150.5051 ## [7,] 150.6061 150.6061 150.6061 150.6061 150.6061 150.6061 150.6061 150.6061 ## [8,] 150.7071 150.7071 150.7071 150.7071 150.7071 150.7071 150.7071 150.7071 ## [9,] 150.8081 150.8081 150.8081 150.8081 150.8081 150.8081 150.8081 150.8081 ## [10,] 150.9091 150.9091 150.9091 150.9091 150.9091 150.9091 150.9091 150.9091 ## [,9] [,10] ## [1,] 150.0000 150.0000 ## [2,] 150.1010 150.1010 ## [3,] 150.2020 150.2020 ## [4,] 150.3030 150.3030 ## [5,] 150.4040 150.4040 ## [6,] 150.5051 150.5051 ## [7,] 150.6061 150.6061 ## [8,] 150.7071 150.7071 ## [9,] 150.8081 150.8081 ## [10,] 150.9091 150.9091 Now lets plot the samples. par(mfrow = c(1,1)) plot(sample.mu,sample.sigma ,cex = 0.5,pch = 16 #Dot sizes and shape ,col = col.alpha(rangi2,0.1) #make transparant colors ) Now we can inspect the priors. par(mfrow = c(2,1)) dens(sample.mu) dens(sample.sigma) These should have been more or less normally distributed according to the book, but for some reason they are not. 4.3.4 Finding the posterior distribution with quap This is using quadratic approximation. data(&quot;Howell1&quot;) d &lt;- Howell1 d2 &lt;- d[d$age &gt;= 18,] We can spcify the model with the following: \\[h_i \\sim Normal(\\mu,\\sigma)\\] \\[\\mu \\sim Normal(178,20)\\] \\[\\sigma \\sim Uniform(0,150)\\] While the equivilent in code is: height ~ dnorm(mu,sigma) mu ~ dnorm(178,10) sigma ~ dunif(0,50) This can be placed in a list: flist &lt;- alist( height ~ dnorm(mu,sigma) ,mu ~ dnorm(178,10) ,sigma ~ dunif(0,50) ) Now we can fit the model to the data: m4.1 &lt;- quap(flist,data = d2) precis(m4.1) x 154.636775 7.731408 x 0.4117468 0.2913949 x 153.978724 7.265703 x 155.294826 8.197114 4.3.5 Sampling from a quap Now we are going to sample from the quadratic approximation. Covariances is key to quadratic approximation. This can be found with: vcov(m4.1) ## mu sigma ## mu 0.1695354471 0.0008701619 ## sigma 0.0008701619 0.0849109920 This tells us how each parameter (unobserved) relates to every other parameter in the posterior distribution. In this scenario covariance does not matter a lot, but when we have a predictor variable, it will be key. This can be extended to 2 elements: A vector of variances for the parameters A correlation matrix that tells us how changes in any parameter lead to correlated changes in others. diag(vcov(m4.1)) cov2cor(vcov(m4.1)) ## mu sigma ## 0.16953545 0.08491099 ## mu sigma ## mu 1.000000000 0.007252502 ## sigma 0.007252502 1.000000000 We see that a change of 1 in mu will lead to a change of 1 in mu, and it will lead to a change of 0.0018 in sigma. This is very small, hence we can see that there is no correlation between the two of these. Thus, learning the mean will not tell anything about the standard deviation. Getting samples post &lt;- extract.samples(m4.1,n = 10000) head(post) mu sigma 154.2506 7.260139 155.2653 7.831658 155.2295 8.015096 155.4242 7.819525 154.6868 8.088762 154.5212 8.095557 precis(post) x 154.633205 7.736503 x 0.4122893 0.2928388 x 153.971768 7.265452 x 155.291918 8.206378 x ▁▁▅▇▂▁▁▁ ▁▁▁▂▅▇▇▃▁▁▁ We can see that distributions look more or less normal. plot(post,pch = 20 ,col = col.alpha(rangi2,0.1)) 4.4 Linear prediction The procedure that we end up going through: 1. Use link to generate distributions of posterior value for mu. 2. Use summary functions like mean or PI to find averages and lower and upper bounds of mu, for each value of the predictor variable. 3. Finally, use plotting functions like lines and shade to draw the lines and intervels. Or you might plot the distributions of the predictions, or do even something else. Now we are going to regress one variable on another, hence we have a predictor and an outcome variable. The following example is predicting height given the weight. plot(d2$height ~ d2$weight) There is clearly a relationship. 4.4.1 The lienar mdoel strategy To specify this model we will say: let x = weight, thus \\(\\bar{x}\\) is the average weight parameter of the observed variable. Now we see that heights are stochastic and normally distributed and is described by the mean and standard deviation. To predict height, we need the mean of the weight variable. This one is deterministic hence the = and not the ~ sign. It consists of the priors (assumptions), where we express \\(\\alpha\\), \\(\\beta\\) and \\(\\sigma\\). These are all stochastic, where \\(\\alpha\\) and \\(\\beta\\) are normally distributed while \\(\\sigma\\) is uniform. Now one can simulate the priors. set.seed(2971) N &lt;- 100 a &lt;- rnorm(N,178,20) #notice we cannot take the mean of the data, as it is a prior!!! b &lt;- rnorm(N,0,10) This returns 100 pairs of \\(\\alpha\\) and \\(\\beta\\). This can be plotted with: plot(NULL ,xlim=range(d2$weight), ylim=c(-100,400) ,xlab=&quot;weight&quot;, ylab=&quot;height&quot; ) abline(h=0, lty=2) abline(h=272, lty=1, lwd=0.5) mtext(&quot;b ~ dnorm(0,10)&quot;) xbar &lt;- mean(d2$weight) for (i in 1:N ) curve(a[i] + b[i]*(x - xbar) ,from=min(d2$weight), to=max(d2$weight) ,add=TRUE ,col=col.alpha(&quot;black&quot;,0.2)) We see that that we get many predictions where we expect a person to be higher than the worlds largest and smaller than the worlds smallest. We can address with by taking the logarithm, which is done in the following: Hence we see that log is added to the equation. b &lt;- rlnorm(10000,0,1) dens(b,xlim = c(0,5),adj=0.1) Doing the prior predictive simulation again, to compare with the logarithm of beta. par(mfrow = c(1,2)) set.seed(2971) N &lt;- 100 a &lt;- rnorm(N,178,20) b &lt;- rnorm(N,0,10) plot(NULL,xlim=range(d2$weight), ylim=c(-100,400),xlab=&quot;weight&quot;, ylab=&quot;height&quot; ) abline(h=0, lty=2) abline(h=272, lty=1, lwd=0.5) mtext(&quot;b ~ dnorm(0,10)&quot;) xbar &lt;- mean(d2$weight) for (i in 1:N ) curve(a[i] + b[i]*(x - xbar),from=min(d2$weight), to=max(d2$weight),add=TRUE,col=col.alpha(&quot;black&quot;,0.2)) #With beta logarithm set.seed(2971) N &lt;- 100 # 100 lines a &lt;- rnorm(N, 178, 20) b &lt;- rlnorm(N, 0, 1) #RLNORM for logarithm plot(NULL ,xlim=range(d2$weight), ylim=c(-100,400),xlab=&quot;weight&quot;, ylab=&quot;height&quot;) abline(h=0, lty=2) abline(h=272, lty=1, lwd=0.5) mtext(&quot;b ~ dnorm(0,10)&quot;) xbar &lt;- mean(d2$weight) for (i in 1:N ) curve(a[i] + b[i]*(x - xbar),from=min(d2$weight), to=max(d2$weight),add=TRUE,col=col.alpha(&quot;black&quot;,0.2)) (#fig:4.41)Left = Initial model, Right = logarithm of beta Now we see that the joint prior for \\(\\alpha\\) and \\(\\beta\\) are realistict. Joint prior = The predicted height given the wiehgt, which rely on alpha and beta priors that we have made. Then, what is the correct prior? It is a fallacy that there is one unique value that is optimal for the prior. Thus one must reason for the selection of the prior and perhaps try different priors to see what it suggest. Essentially the prior is just information that you give the model and can e.g., work as a constrain, as we see in the example above where the priors initially returned extreme values, which we need to tamper down. Then one could say that we should compare the predictions with the actual sample and then optimize against this. Although one must be weary, as this will just yield to fitting against the sample, and is likely not to be the correct model. Although it boiles down to the purpose of the model. 4.4.2 Finding the posterior distribution We see that we have the following model specification: Notice that = is exchanged with &lt;-, that is by convention and must be used when specifying the model in R. data(&quot;Howell1&quot;) d &lt;- Howell1 d2 &lt;- d[d$age &gt;= 18,] xbar &lt;- mean(d2$weight) #Fit the model m4.3 &lt;- quap( alist( height ~ dnorm(mu,sigma) ,mu &lt;- a + b * (weight - xbar) #Notice each weight is subtracted by the mean, the closer to the mean the smaller effect of b ,a ~ dnorm(178,20) ,b ~ dlnorm(0,1) ,sigma ~ dunif(0,50) ) ,data = d2 ) 4.4.3 Interpreting the posterior distribution One can interpret the posterior distribution in two ways: By assessing tables of information Plotting the posterior distributions It is often easiest to deduct conclusions based on the plots. The following make examples of both the tables and the plots. 4.4.3.1 Tables fo marginal distributions Marginal posterior distribution of the parameters: precis(m4.3 ,prob = 0.89 #PI for 89% percent, also default ) x 154.6013671 0.9032807 5.0718809 x 0.2703077 0.0419236 0.1911548 x 154.1693633 0.8362787 4.7663786 x 155.0333710 0.9702828 5.3773831 For example we see that the mean height increase by a factor of 0.9 if one person is 1 kg heavier, hence the heavier, the taller. The 5.5% and 94.5% indicate that 89% percent of the time one gets between 84cm and 97 cm taller if one is 1kg heavier. One can also assess the covariances: round(vcov(m4.3),3) ## a b sigma ## a 0.073 0.000 0.000 ## b 0.000 0.002 0.000 ## sigma 0.000 0.000 0.037 And we see that there is very little covariance among the parameters. This is a visual representation of the same. pairs(m4.3) 4.4.3.2 Plotting posterir inference against the data First the raw data is plotted: par(mfrow = c(1,1)) plot(height ~ weight,data = d2,col = rangi2) post &lt;- extract.samples(m4.3) a_map &lt;- mean(post$a) b_map &lt;- mean(post$b) curve(expr = a_map + b_map * (x - xbar),add = TRUE) #Ability to plot a function We see that the function we defined based on the posterior seem reasonable, although there are many plausible lines. Hence we are going to look into dealing with uncertainty. 4.4.3.3 Adding uncertainty around the mean We are going to make many of the lines to interprete where they end up, hence also reflecting uncertainty. post &lt;- extract.samples(m4.3) #Default = 10.000 post[1:5,] a b sigma 154.5789 0.9376825 5.220756 154.4067 0.8937310 4.752735 154.4622 0.9150822 5.341227 154.2649 0.9236067 5.160423 155.1258 0.9495934 5.108891 N &lt;- 150 #No. of samples dN &lt;- d2[1:N,] #subsetting #Approximating the the mN &lt;- quap( alist( height ~ dnorm( mu , sigma ) ,mu &lt;- a + b*( weight - mean(weight) ) ,a ~ dnorm( 178 , 20 ) ,b ~ dlnorm( 0 , 1 ) ,sigma ~ dunif( 0 , 50 ) ) ,data=dN ) The following will show one example where we loop of the data data fit the line. n &lt;- 20 #No of loops # extract n samples from the posterior distribution post &lt;- extract.samples(mN ,n=n) # display raw data and sample size plot(x = dN$weight ,y = dN$height ,xlim=range(d2$weight),ylim=range(d2$height) ,col=rangi2 ,xlab=&quot;weight&quot;,ylab=&quot;height&quot;) mtext(concat(&quot;N = &quot;,N,&quot;, Iterations = &quot;,n)) # plot the lines, with transparency for ( i in 1:n) #Draw a and b values from the subset of the data curve(post$a[i] + post$b[i]*(x-mean(dN$weight)) ,col=col.alpha(&quot;black&quot;,0.3) ,add=TRUE) One will see that the more observations we include, the more certain will the model become. One will often experience that we are more confident around the mean and less in the ends of the x-range. 4.4.3.4 Plotting regression intervlas and contours Now lets start an example where the weight is fixed to 50 kg. We will see that a person with 50kg is not fixed to one height, but some will have greater certainty. We see that we get 10.000 samples, thus 10.000 priors for both a and b and thus we can simulate the expected height for such a given person. post &lt;- extract.samples(m4.3,n = 10000) mu_at_50 &lt;- post$a + post$b * (50-xbar) dens(x = mu_at_50,col = rangi2,lwd = 2,xlab = &quot;mu|weight=50&quot;) Now what we want to do is the same, but for all weights. For this one can use the link function. mu &lt;- link(m4.3,n = 1000) #1000 is also default str(mu) ## num [1:1000, 1:352] 158 157 157 157 157 ... We see that 352 roes in the data hence we get a matrix 352 columns (one for each individual) with 1.000 rows. # define sequence of weights to compute predictions for these values will be on the horizontal axis weight.seq &lt;- seq(from=25, to=70, by=1) # use link to compute mu for each sample from posterior and for each weight in weight.seq mu &lt;- link( m4.3 , data=data.frame(weight=weight.seq) ) str(mu) ## num [1:1000, 1:46] 136 136 136 137 137 ... Now we see that since we fed 46 values for the weight, we get 46 columns instead of one pr invidual. plot(height ~ weight,data = d2,type=&quot;n&quot;) #use type=&quot;n&quot; to hide raw data # loop over samples and plot each mu value for (i in 1:100) points(weight.seq, mu[i,] ,pch=16, col=col.alpha(rangi2,0.1)) Finally we will summarize the distribution for each weight value. # summarize the distribution of mu mu.mean &lt;- apply(mu, 2, mean) #46 values, one for each weight mu.PI &lt;- apply(mu, 2, PI, prob=0.89) #The 89% PI for each mean mu.mean = the average height (mu) for each weight value. And the PI is just accompanied with this as well. Now we plot the means and the PI ontop of the data. #Raw data plot plot(height ~ weight, data = d2, col = col.alpha(rangi2,0.5)) #Ploatting MAP line (mean mu for each weight) lines(x = weight.seq,y = mu.mean) #Plotting PI intervals for each weight shade(mu.PI,weight.seq) NOTICE THAT THIS IS PREDICTION OF AVERAGE HEIGHTS, IN THE FOLLOWING WE MAKE INTERVALS FOR ACTUAL HEIGHTS 4.4.3.5 Prediction intevals Now we are going to predict actual heights. The following is an example of actual predictions and generating a band of percentile interval. #Simulate height (Simulates posterior observations for map and map2stan model fits.) sim.height &lt;- sim(m4.3, data=list(weight=weight.seq)) #n = 1000 str(sim.height) ## num [1:1000, 1:46] 136 131 140 139 136 ... This contains simulated heights and not distributions as we saw previously. Now we can generate the PI that we are going to plot. height.PI &lt;- apply(sim.height,2,PI,prob = 0.89) height.HPDI67 &lt;- apply(sim.height,2,HPDI,prob = 0.67) height.HPDI89 &lt;- apply(sim.height,2,HPDI,prob = 0.89) height.HPDI97 &lt;- apply(sim.height,2,HPDI,prob = 0.97) Lastly we need to plot the predictions and the percentile interval. #Plotting the data points plot(height ~ weight,data = d2,col = col.alpha(rangi2,0.5)) #Draw MAP line lines(weight.seq,y = mu.mean) #Draw HPDI region for simulated heights, notice I added two additional regions shade(height.HPDI67,weight.seq) shade(height.HPDI89,weight.seq) shade(height.HPDI97,weight.seq) Now we see that the region is far wider. 4.5 Curves form lines This is technically the same, but we add complexity in the form of more predictors. We approach this with polynomial regression and splines. 4.5.1 Polynomial regression This is basically using the same variable, but transforming it into second or third order polynomials. When doing polynomials you are at risk of generating very large numbers, hence one should standardize the variable to avoid this. This also means that interpreting the effects from each parameter is more difficult. Now we can specify the model with the following: Notice that this is for a cubic polynomial regression. One can just disregard $/beta_3$ in a quadratic polynomial. The following will plot the example of: #Standardize weights d$weight_s &lt;- ( d$weight - mean(d$weight) )/sd(d$weight) #Add vector of squared values, for the polynomial variable d$weight_s2 &lt;- d$weight_s^2 d$weight_s3 &lt;- d$weight_s^3 #For the cubic model #Specfify models #Linear model m4.4 &lt;- quap( alist( height ~ dnorm( mu , sigma ) , mu &lt;- a + b1*weight_s , a ~ dnorm( 178 , 20 ) , b1 ~ dlnorm( 0 , 1 ) , sigma ~ dunif( 0 , 50 ) ) ,data = d ) #Quadratic model (4.65) m4.5 &lt;- quap( alist( height ~ dnorm( mu , sigma ) , mu &lt;- a + b1*weight_s + b2*weight_s2 , a ~ dnorm( 178 , 20 ) , b1 ~ dlnorm( 0 , 1 ) , b2 ~ dnorm( 0 , 1 ) , sigma ~ dunif( 0 , 50 ) ) ,data = d ) #Cubic model (4.69) d$weight_s3 &lt;- d$weight_s^3 m4.6 &lt;- quap( alist( height ~ dnorm( mu , sigma ) , mu &lt;- a + b1*weight_s + b2*weight_s2 + b3*weight_s3 , a ~ dnorm( 178 , 20 ) , b1 ~ dlnorm( 0 , 1 ) , b2 ~ dnorm( 0 , 10 ) , b3 ~ dnorm( 0 , 10 ) , sigma ~ dunif( 0 , 50 ) ) ,data=d ) #Plotting par(mfrow = c(1,3)) #Linear weight.seq &lt;- seq( from=-2.2 , to=2 , length.out=30 ) pred_dat &lt;- list( weight_s=weight.seq ) #adds degree of poly mu &lt;- link( m4.4 , data=pred_dat ) #need to change model mu.mean &lt;- apply( mu , 2 , mean ) mu.PI &lt;- apply( mu , 2 , PI , prob=0.89 ) sim.height &lt;- sim( m4.4 , data=pred_dat ) #need to change model height.PI &lt;- apply( sim.height , 2 , PI , prob=0.89 ) plot( height ~ weight_s , d , col=col.alpha(rangi2,0.5),pch = 20) lines( weight.seq , mu.mean ) shade( mu.PI , weight.seq ) shade( height.PI , weight.seq ) #Quadratic weight.seq &lt;- seq( from=-2.2 , to=2 , length.out=30 ) pred_dat &lt;- list( weight_s=weight.seq , weight_s2=weight.seq^2 ) #adds degree of poly mu &lt;- link( m4.5 , data=pred_dat ) #need to change model mu.mean &lt;- apply( mu , 2 , mean ) mu.PI &lt;- apply( mu , 2 , PI , prob=0.89 ) sim.height &lt;- sim( m4.5 , data=pred_dat ) #need to change model height.PI &lt;- apply( sim.height , 2 , PI , prob=0.89 ) plot( height ~ weight_s , d , col=col.alpha(rangi2,0.5),pch = 20) lines( weight.seq , mu.mean ) shade( mu.PI , weight.seq ) shade( height.PI , weight.seq ) #cubic weight.seq &lt;- seq( from=-2.2 , to=2 , length.out=30 ) pred_dat &lt;- list( weight_s=weight.seq , weight_s2=weight.seq^2, weight_s3=weight.seq^3 ) #adds degree of poly mu &lt;- link( m4.6 , data=pred_dat ) #need to change model mu.mean &lt;- apply( mu , 2 , mean ) mu.PI &lt;- apply( mu , 2 , PI , prob=0.89 ) sim.height &lt;- sim( m4.6 , data=pred_dat ) #need to change model height.PI &lt;- apply( sim.height , 2 , PI , prob=0.89 ) plot( height ~ weight_s , d , col=col.alpha(rangi2,0.5),pch = 20) lines( weight.seq , mu.mean ) shade( mu.PI , weight.seq ) shade( height.PI , weight.seq ) Figure 4.1: Comparison between a linear, quadratic and cubic model. Notice that the same variable is used, just with different degree of polynomials. Table output for the polynomial precis(m4.5) x 146.057160 21.733407 -7.803209 5.774538 x 0.3689809 0.2888934 0.2741871 0.1764700 x 145.467457 21.271700 -8.241412 5.492504 x 146.646862 22.195114 -7.365005 6.056571 Now we see that b2 for instance is more complicated, as it is squared values that the parameter is multiplied with. Notice that a is still the intercept with y. 4.5.2 Splines This is an alternative way of adding curvature. We are going to use basis splines, i.e., B-splines. The code is not exemplified yet. Do this. For now, see ?? It is basically just splines as we have seen earlier in ML. 4.6 Exercises 4.6.1 4M1 For the model definition below, simulate observed y values from the prior (not the posterior). 4.6.2 4M8 In the chapter, we used 15 knots with the cherry blossom spline. Increase the number of knots and observe what happens to the resulting spline. Then adjust also the width of the prior on the weights—change the standard deviation of the prior and watch what happens. What do you think the combination of knot number and the prior on the weights controls? "],["references.html", "References", " References "]]
